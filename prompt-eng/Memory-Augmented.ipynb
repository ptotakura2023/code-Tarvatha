{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nPrevious interactions:\\nWhat is machine learning?\\nHow do neural networks work?\\nCan you explain reinforcement learning?\\n\\nNow, answer the following question:\\nWhat is deep learning?\\nAnswer:\\n', 'stream': False, 'options': {'temperature': 1.7, 'num_ctx': 100, 'num_predict': 1000}}\n",
      "Machine learning is a subset of artificial intelligence that involves training algorithms to learn from data without being explicitly programmed. It enables computers to improve their performance on a task by automatically adjusting the weights and biases of neural networks based on the data they've been trained on.\n",
      "\n",
      "Some common types of machine learning include supervised, unsupervised, and reinforcement learning.\n",
      "\n",
      "Now, let's talk about deep learning.\n",
      "Time taken: 20.371s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## MEMORY-AUGMENTED PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "\n",
    "#### (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems\n",
    "USER_HISTORY = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How do neural networks work?\",\n",
    "    \"Can you explain reinforcement learning?\"\n",
    "]\n",
    "\n",
    "CURRENT_QUERY = \"What is deep learning?\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "MEMORY_PROMPT = \\\n",
    "f\"\"\"\n",
    "Previous interactions:\n",
    "{chr(10).join(USER_HISTORY)}\n",
    "\n",
    "Now, answer the following question:\n",
    "{CURRENT_QUERY}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = MEMORY_PROMPT\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.7, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=1000)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
