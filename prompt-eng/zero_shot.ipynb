{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting refers to a technique in prompt engineering where you provide a model with a task without any prior examples. The model is expected to understand and generate a response or complete the task purely based on the given instruction.\n",
    "\n",
    "In other words, the model is given \"zero\" prior training examples or demonstrations in the prompt and relies on its pre-trained knowledge to infer what is needed.\n",
    "\n",
    "## References:\n",
    "* [Wei et al. (2022)](https://arxiv.org/pdf/2109.01652.pdf): demonstrate how instruction tuning improves zero-shot learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': \"\\nYou are an expert in **Requirement Analysis** for AI-based applications.  \\nGenerate a **structured Requirement Analysis Document** for the given project description.  \\n\\n---\\n### **Project Description:**  \\nWe plan to build a Discord Bot that helps students in answering their queries, \\nfetch additional info through web search, and utilize GenAI capabilities to improve response quality and personalization.\\n\\n### **Requirement Analysis Document:**  \\n1. **Objective:**  \\n   - Clearly define the project's purpose.  \\n\\n2. **Functional Requirements:**  \\n   - List key features and capabilities.  \\n\\n3. **Non-Functional Requirements:**  \\n   - Define performance, security, and scalability needs.  \\n\\n4. **User Stories:**  \\n   - Capture the system's behavior from a user's perspective.  \\n\\n5. **System Components:**  \\n   - Identify core modules and technologies.  \\n\\n6. **Constraints:**  \\n   - Mention any project limitations.  \\n\", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 1000}}\n",
      "**Project: Bot Assistant Chatbot**\n",
      "\n",
      "**1. Project Purpose**\n",
      "\n",
      "The purpose of this project is to develop a conversational chatbot that assists users in various tasks, providing helpful information, and automating routine inquiries.\n",
      "\n",
      "**2. Functional Requirements**\n",
      "\n",
      "* User authentication and authorization\n",
      "* Natural Language Processing (NLP) for text input recognition\n",
      "* Knowledge base management with database integration\n",
      "* Integration with third-party APIs for external data access\n",
      "* Emotion detection and response to user emotional states\n",
      "* Conversational flow management and state transition\n",
      "* Personalization and profile management\n",
      "\n",
      "**3. Non-Functional Requirements**\n",
      "\n",
      "* Response time < 2 seconds for text queries\n",
      "* Error handling and logging mechanism\n",
      "* Security and data encryption measures\n",
      "* Scalability and performance optimization\n",
      "* Integration with multiple platforms (web, mobile, etc.)\n",
      "\n",
      "**4. System Design**\n",
      "\n",
      "The chatbot will be built using a microservices architecture, consisting of:\n",
      "\n",
      "* **NLP Service**: Responsible for processing user input and generating responses.\n",
      "* **Conversation Service**: Manages the conversational flow and state transition.\n",
      "* **Data Service**: Handles user profile management and personalization.\n",
      "* **API Gateway**: Acts as an entry point for external requests.\n",
      "\n",
      "**5. Technical Requirements**\n",
      "\n",
      "* **Backend**: Node.js, Express.js, or Django (depending on team preference)\n",
      "* **Frontend**: React.js, Angular.js, or Vue.js\n",
      "* **Database**: Relational or NoSQL database (e.g., PostgreSQL, MongoDB)\n",
      "\n",
      "Now it's your turn! Can you guess what this text is?\n",
      "Time taken: 40.425s\n"
     ]
    }
   ],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Define the Project Description  \n",
    "MESSAGE = \"\"\"We plan to build a Discord Bot that helps students in answering their queries, \n",
    "fetch additional info through web search, and utilize GenAI capabilities to improve response quality and personalization.\"\"\"  \n",
    "\n",
    "#### (2) Define the Zero-Shot Prompt  \n",
    "PROMPT = f\"\"\"\n",
    "You are an expert in **Requirement Analysis** for AI-based applications.  \n",
    "Generate a **structured Requirement Analysis Document** for the given project description.  \n",
    "\n",
    "---\n",
    "### **Project Description:**  \n",
    "{MESSAGE}\n",
    "\n",
    "### **Requirement Analysis Document:**  \n",
    "1. **Objective:**  \n",
    "   - Clearly define the project's purpose.  \n",
    "\n",
    "2. **Functional Requirements:**  \n",
    "   - List key features and capabilities.  \n",
    "\n",
    "3. **Non-Functional Requirements:**  \n",
    "   - Define performance, security, and scalability needs.  \n",
    "\n",
    "4. **User Stories:**  \n",
    "   - Capture the system's behavior from a user's perspective.  \n",
    "\n",
    "5. **System Components:**  \n",
    "   - Identify core modules and technologies.  \n",
    "\n",
    "6. **Constraints:**  \n",
    "   - Mention any project limitations.  \n",
    "\"\"\"\n",
    "\n",
    "#### (3) Configure the Model Request  \n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0,  \n",
    "                         num_ctx=200, \n",
    "                         num_predict=1000) \n",
    "\n",
    "### Send the request to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f\"Time taken: {time}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to improve it?\n",
    "\n",
    "* **Use Clear and Concise Instructions**: Be specific about the task and desired format.\n",
    "    * Bad Prompt: “Summarize this.”\n",
    "    * Good Prompt: “Summarize this paragraph in one sentence.”\n",
    "* **Add Context**: Providing background can help the model interpret ambiguous prompts better.\n",
    "* **Specify Output Format**: If a particular structure is needed, describe it in the instruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
